# streamlit_app.py (‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡πÉ‡∏´‡∏°‡πà ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢+‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©)
import os, math, json, sys
import joblib
import pandas as pd
import numpy as np
import streamlit as st
from locations_th import PROV_TO_DIST, DIST_TO_SUB, SUB_TO_STREET, STREET_TO_ZONE
from sklearn.metrics.pairwise import cosine_similarity

# ---------- Setup ----------
st.set_page_config(page_title="Condo Price Predictor", page_icon="üè¢", layout="wide")

FLAGS = ["is_pool_access", "is_corner", "is_high_ceiling"]  # ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏•‡πá‡∏≠‡∏Å = 0 ‡πÄ‡∏™‡∏°‡∏≠

NUM_FEATURES = [
    "Area_sqm", "Project_Age_notreal", "Floors", "Total_Units",
    "Launch_Month_sin", "Launch_Month_cos",
] + FLAGS  # ‡∏¢‡∏±‡∏á‡∏ï‡πâ‡∏≠‡∏á‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô ALL_FEATURES ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•

CAT_FEATURES = [
    "Room_Type_Base", "Province", "District", "Subdistrict", "Street", "Zone"
]
ALL_FEATURES = NUM_FEATURES + CAT_FEATURES
PIPELINE_FILE = "pipeline.pkl"


# ---------- Helpers ----------
def month_to_sin_cos(m: int):
    rad = 2 * math.pi * (m - 1) / 12.0
    return math.sin(rad), math.cos(rad)

def safe_float(x, default=0.0):
    try: return float(x)
    except: return float(default)
        
def ensure_columns(df: pd.DataFrame, cols: list, fill_value_map: dict = None) -> pd.DataFrame:
    """‡∏ó‡∏≥‡πÉ‡∏´‡πâ df ‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö cols ‡∏ó‡∏∏‡∏Å‡∏ï‡∏±‡∏ß; ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÉ‡∏´‡πâ‡πÄ‡∏ï‡∏¥‡∏° ‡πÅ‡∏•‡∏∞‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ô"""
    df = df.copy()
    fill_value_map = fill_value_map or {}
    for c in cols:
        if c not in df.columns:
            df[c] = fill_value_map.get(c, 0)
    # ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÄ‡∏Å‡∏¥‡∏ô‡∏°‡∏≤ ‡∏õ‡∏•‡πà‡∏≠‡∏¢‡πÑ‡∏ß‡πâ‡πÑ‡∏î‡πâ ‡πÅ‡∏ï‡πà‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ
    return df[cols]


from sklearn.metrics.pairwise import cosine_similarity
from sklearn.preprocessing import StandardScaler


def flexible_selectbox(label, options):
    """‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏à‡∏≤‡∏Å list ‡∏´‡∏£‡∏∑‡∏≠‡∏û‡∏¥‡∏°‡∏û‡πå‡πÄ‡∏≠‡∏á‡πÑ‡∏î‡πâ (return ‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å/‡∏û‡∏¥‡∏°)"""
    extended_options = options + ["‡∏≠‡∏∑‡πà‡∏ô ‡πÜ (‡∏û‡∏¥‡∏°‡∏û‡πå‡πÄ‡∏≠‡∏á)"]
    choice = st.selectbox(label, extended_options)
    if choice == "‡∏≠‡∏∑‡πà‡∏ô ‡πÜ (‡∏û‡∏¥‡∏°‡∏û‡πå‡πÄ‡∏≠‡∏á)":
        manual_value = st.text_input(f"‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏û‡∏¥‡∏°‡∏û‡πå {label} ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£")
        return manual_value.strip()
    else:
        return choice
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline

def _which_side(pipeline, X_one_row):
    """‡∏ö‡∏≠‡∏Å‡∏ß‡πà‡∏≤‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡πÅ‡∏ñ‡∏ß‡∏ô‡∏µ‡πâ‡πÉ‡∏ä‡πâ MASS ‡∏´‡∏£‡∏∑‡∏≠ LUX"""
    # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô TwoSegmentRegressor (area-rule 250 ‡∏ï‡∏£.‡∏°.)
    if hasattr(pipeline, "predict"):
        try:
            # ‡∏ñ‡πâ‡∏≤‡∏Ñ‡∏•‡∏≤‡∏™‡∏Ñ‡∏∏‡∏ì‡∏°‡∏µ‡πÄ‡∏°‡∏ò‡∏≠‡∏î‡∏†‡∏≤‡∏¢‡πÉ‡∏ô‡∏ö‡∏≠‡∏Å‡∏ù‡∏±‡πà‡∏á‡∏ä‡∏±‡∏î ‡πÜ ‡∏Å‡πá‡πÉ‡∏ä‡πâ‡πÄ‡∏•‡∏¢
            pass
        except:
            pass
    # fallback ‡πÅ‡∏ö‡∏ö‡∏á‡πà‡∏≤‡∏¢ (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ Area_sqm)
    return "LUX" if float(X_one_row.get("Area_sqm", 0)) > 250 else "MASS"

def _encode_like_model(pipeline, X_df, cat_cols, side):
    """‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡∏£‡∏´‡∏±‡∏™‡πÅ‡∏ö‡∏ö‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•; ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ ‡πÉ‡∏´‡πâ one-hot ‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß"""
    X_df = X_df.copy()
    if side == "LUX" and hasattr(pipeline, "lux_encoder") and pipeline.lux_encoder is not None:
        X_df[cat_cols] = pipeline.lux_encoder.transform(X_df[cat_cols])
        return X_df, "model"
    if side == "MASS" and hasattr(pipeline, "mass_encoder") and pipeline.mass_encoder is not None:
        X_df[cat_cols] = pipeline.mass_encoder.transform(X_df[cat_cols])
        return X_df, "model"

    # ---- fallback: one-hot ‡∏ó‡∏±‡πâ‡∏á‡∏ä‡∏∏‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô ----
    pre = ColumnTransformer([
        ("num", "passthrough", [c for c in X_df.columns if c not in cat_cols]),
        ("cat", OneHotEncoder(handle_unknown="ignore", sparse_output=False), cat_cols),
    ])
    enc = Pipeline([("pre", pre)])
    X_arr = enc.fit_transform(X_df)   # fit ‡∏î‡πâ‡∏ß‡∏¢ train ‡∏£‡∏ß‡∏° input 1 ‡πÅ‡∏ñ‡∏ß
    X_encoded = pd.DataFrame(X_arr)
    return X_encoded, "onehot"

def compute_confidence_robust(pipeline, X_train_all, X_input_one, all_cols, cat_cols, top_k=5):
    # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏ä‡∏∏‡∏î‡πÉ‡∏´‡πâ‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏Ñ‡∏£‡∏ö
    X_train_used = X_train_all.reindex(columns=all_cols).copy()
    X_input = X_input_one.reindex(columns=all_cols).copy()

    # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ù‡∏±‡πà‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• (MASS/LUX) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ñ‡∏ß‡∏ô‡∏µ‡πâ
    side = _which_side(pipeline, X_input.iloc[0].to_dict())

    # ‡πÄ‡∏Ç‡πâ‡∏≤‡∏£‡∏´‡∏±‡∏™‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡πÅ‡∏ö‡∏ö‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏• (‡∏´‡∏£‡∏∑‡∏≠ one-hot fallback)
    X_train_enc, mode1 = _encode_like_model(pipeline, X_train_used, cat_cols, side)
    # ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç: ‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ encoder ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô‡∏Å‡∏±‡∏ö train ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô
    if mode1 == "model":
        X_input_enc, _ = _encode_like_model(pipeline, X_input, cat_cols, side)
    else:
        # one-hot ‡πÉ‡∏´‡∏°‡πà ‡∏ï‡πâ‡∏≠‡∏á fit ‡∏à‡∏≤‡∏Å train+input ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô‡πÉ‡∏´‡πâ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ï‡∏£‡∏á
        combo = pd.concat([X_train_used, X_input], axis=0)
        X_combo_enc, _ = _encode_like_model(pipeline, combo, cat_cols, side)
        X_train_enc = X_combo_enc.iloc[:-1, :].reset_index(drop=True)
        X_input_enc = X_combo_enc.iloc[-1:, :].reset_index(drop=True)

    # ‡∏™‡πÄ‡∏Å‡∏•‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì cosine
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train_enc)
    X_new_scaled = scaler.transform(X_input_enc)

    sim = cosine_similarity(X_train_scaled, X_new_scaled).ravel()
    k = min(top_k, len(sim))
    conf = float(np.mean(np.sort(sim)[-k:]))
    return conf


# ---------- Load model ----------
try:
    import two_segment
    sys.modules['main'] = two_segment
except Exception:
    pass

if not os.path.exists(PIPELINE_FILE):
    st.error(f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå {PIPELINE_FILE} ‚Äî ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ß‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏ß‡πâ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå")
    st.stop()

try:
    pipeline = joblib.load(PIPELINE_FILE)
    st.sidebar.success("‡πÇ‡∏´‡∏•‡∏î pipeline.pkl ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à ‚úÖ")
except Exception as e:
    st.error(f"‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {e}")
    st.stop()

# ---------- ‡πÇ‡∏´‡∏•‡∏î X_train (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Confidence) ----------
try:
    X_train_all = joblib.load("X_train.pkl")
except:
    st.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö X_train.pkl ‚Äî ‡∏à‡∏∞‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏™‡∏î‡∏á Confidence Score ‡πÑ‡∏î‡πâ")
    X_train_all = None


# ---------- UI ----------
st.title("üè¢ Condo Price Predictor")
st.caption("‡∏Å‡∏£‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‚Üí ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏£‡∏≤‡∏Ñ‡∏≤‡∏Ç‡∏≤‡∏¢ (‡∏•‡πâ‡∏≤‡∏ô‡∏ö‡∏≤‡∏ó) ‡πÅ‡∏•‡∏∞‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ï‡πà‡∏≠‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÄ‡∏°‡∏ï‡∏£ (‡∏ö‡∏≤‡∏ó/‡∏ï‡∏£.‡∏°.)")

col1, col2, col3 = st.columns(3)
with col1:
    area_input = st.text_input("‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà (‡∏ï‡∏£.‡∏°.) ‚Äî Area_sqm", value="30")
    try: area = float(area_input)
    except: area = 0.0

    floors_input = st.text_input("‡∏ä‡∏±‡πâ‡∏ô‡∏≠‡∏≤‡∏Ñ‡∏≤‡∏£ ‚Äî Floors", value="8")
    try: floors = int(floors_input)
    except: floors = 1

with col2:
    age_input = st.text_input("‡∏≠‡∏≤‡∏¢‡∏∏‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£ (‡∏õ‡∏µ) ‚Äî Project_Age", value="0")
    try: age = float(age_input)
    except: age = 0.0

    total_units_input = st.text_input("‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏¢‡∏π‡∏ô‡∏¥‡∏ï‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î ‚Äî Total_Units", value="300")
    try: total_units = int(total_units_input)
    except: total_units = 100

with col3:
    month = st.selectbox("‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡πÄ‡∏õ‡∏¥‡∏î‡∏ï‡∏±‡∏ß ‚Äî Launch Month", options=list(range(1,13)), index=0)
    m_sin, m_cos = month_to_sin_cos(month)

# üè¢ ‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ö‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î-‡∏≠‡∏≥‡πÄ‡∏†‡∏≠-‡∏ï‡∏≥‡∏ö‡∏•-‡∏ñ‡∏ô‡∏ô
province = flexible_selectbox("‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î - Province", sorted(PROV_TO_DIST))
district = flexible_selectbox("‡πÄ‡∏Ç‡∏ï/‡∏≠‡∏≥‡πÄ‡∏†‡∏≠ - District", PROV_TO_DIST.get(province, []))
subdistrict = flexible_selectbox("‡πÅ‡∏Ç‡∏ß‡∏á/‡∏ï‡∏≥‡∏ö‡∏• - Subdistrict", DIST_TO_SUB.get(district, []))
street = flexible_selectbox("‡∏ñ‡∏ô‡∏ô - Street", SUB_TO_STREET.get(subdistrict, []))


# üåê Zone (auto from street)
zone = STREET_TO_ZONE.get(street, "")
st.text_input("Zone (auto)", value=zone)







room_type_base = st.selectbox("‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏´‡πâ‡∏≠‡∏á ‚Äî Room_Type", options = [
    'STUDIO', '2BED', '3BED', '1BED', '1BED_PLUS', 'PENTHOUSE', '2BED_DUPLEX',
    '1BED_DUPLEX', 'DUPLEX_OTHER', '4BED', 'POOL_VILLA', '4BED_PENTHOUSE',
    '3BED_DUPLEX', '1BED_LOFT', '3BED_TRIPLEX', '3BED_PENTHOUSE', '4BED_DUPLEX',
    '5BED_DUPLEX', '2BED_PLUS', 'PENTHOUSE_DUPLEX', 'Pool Access(‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏™‡∏£‡∏∞‡∏ß‡πà‡∏≤‡∏¢‡∏ô‡πâ‡∏≥)',
    '5BED', 'MOFF-Design', '25BED', 'LOFT_OTHER', '2BED_PENTHOUSE', 'SHOP',
    '1BED_PLUS_LOFT', '2BED_LOFT', 'Stuio vertiplex', '3BED_PLUS', '3BED_PLUS_DUPLEX',
    '3BED_LOFT', '4BED_LOFT', 'DUO', '1BED_TRIPLEX', '1BED_PLUS_TRIPLEX',
    '2BED_TRIPLEX', 'Simplex'])



# ‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á row ‡∏Å‡πà‡∏≠‡∏ô (‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏≠‡∏¥‡∏ô‡∏û‡∏∏‡∏ï‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö FLAGS)
row = {
    "Area_sqm": area,
    "Project_Age_notreal": age,
    "Floors": floors,
    "Total_Units": total_units,
    "Launch_Month_sin": m_sin,
    "Launch_Month_cos": m_cos,
    "Province": province,
    "District": district,
    "Subdistrict": subdistrict,
    "Street": street,
    "Zone": zone,
    "Room_Type_Base": room_type_base,
    "is_pool_access": 0,
    "is_corner": 0,
    "is_high_ceiling": 0,
}


# ‚úÖ ‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡πà‡∏≠‡∏¢‡∏™‡∏£‡πâ‡∏≤‡∏á DataFrame X
X = pd.DataFrame([row], columns=ALL_FEATURES)

# ‚úÖ ‡∏Ñ‡πà‡∏≠‡∏¢‡∏°‡∏≤‡πÄ‡∏ä‡πá‡∏Ñ unseen values
unseen_cols = []
if 'X_train_all' in globals() and X_train_all is not None:
    for col in ALL_FEATURES:
        if col not in X.columns or col not in X_train_all.columns:
            continue
        user_value = X[col].values[0]
        unique_values = X_train_all[col].unique()

        if X[col].dtype == 'object' and user_value not in unique_values:
            unseen_cols.append(col)

if unseen_cols:
    st.warning(f"‚ö†Ô∏è ‡∏Ñ‡πà‡∏≤‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ‡πÑ‡∏°‡πà‡πÄ‡∏Ñ‡∏¢‡∏õ‡∏£‡∏≤‡∏Å‡∏è‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•: {', '.join(unseen_cols)}")


# ---------- Predict ----------
if st.button("Predict Price (‡∏•‡πâ‡∏≤‡∏ô‡∏ö‡∏≤‡∏ó)"):
    try:
        # ===== ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏£‡∏≤‡∏Ñ‡∏≤ =====
        y_pred = pipeline.predict(X)
        pred_val = float(np.ravel(y_pred)[0])
        st.metric("‡∏£‡∏≤‡∏Ñ‡∏≤‡∏Ñ‡∏≤‡∏î‡∏Å‡∏≤‡∏£‡∏ì‡πå (‡∏•‡πâ‡∏≤‡∏ô‡∏ö‡∏≤‡∏ó)", f"{pred_val:.3f}")

        price_per_sqm = (pred_val * 1_000_000.0) / max(1.0, safe_float(area, 1.0))
        st.metric("‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ï‡πà‡∏≠‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÄ‡∏°‡∏ï‡∏£ (‡∏ö‡∏≤‡∏ó/‡∏ï‡∏£.‡∏°.)", f"{price_per_sqm:,.0f}")

        # ===== ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Confidence =====
        if X_train_all is not None:
            try:
                # 1) ‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏ó‡∏µ‡πà‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏Ñ‡∏¢‡πÄ‡∏ó‡∏£‡∏ô ‡πÅ‡∏•‡∏∞‡πÄ‡∏ï‡∏¥‡∏° FLAGS=0
                fill0 = {"is_pool_access":0, "is_corner":0, "is_high_ceiling":0}
                X_train_used = ensure_columns(X_train_all, ALL_FEATURES, fill_value_map=fill0)
                X_input_used = ensure_columns(X,            ALL_FEATURES, fill_value_map=fill0)

                # 2) ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ù‡∏±‡πà‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• (‡∏ï‡∏≤‡∏° area-rule 250 ‡∏ï‡∏£.‡∏°.)
                side = "LUX" if float(X_input_used.loc[0, "Area_sqm"]) > 250 else "MASS"

                # 3) ‡πÄ‡∏Ç‡πâ‡∏≤‡∏£‡∏´‡∏±‡∏™‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô encoder ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏à‡∏£‡∏¥‡∏á
                def encode_with_model(pipeline, Xdf, cat_cols, side):
                    Xdf = Xdf.copy()
                    if side == "LUX" and hasattr(pipeline, "lux_encoder") and pipeline.lux_encoder is not None:
                        Xdf[cat_cols] = pipeline.lux_encoder.transform(Xdf[cat_cols])
                        return Xdf
                    if side == "MASS" and hasattr(pipeline, "mass_encoder") and pipeline.mass_encoder is not None:
                        Xdf[cat_cols] = pipeline.mass_encoder.transform(Xdf[cat_cols])
                        return Xdf
                    return Xdf  # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ encoder

                X_train_enc = encode_with_model(pipeline, X_train_used, CAT_FEATURES, side)
                X_input_enc = encode_with_model(pipeline, X_input_used, CAT_FEATURES, side)

                # 4) ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÄ‡∏õ‡πá‡∏ô object ‡∏≠‡∏¢‡∏π‡πà ‚Üí one-hot ‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß
                needs_onehot = any(getattr(X_train_enc[c], "dtype", None) == "object" for c in CAT_FEATURES)
                if needs_onehot:
                    from sklearn.preprocessing import OneHotEncoder
                    from sklearn.compose import ColumnTransformer
                    from sklearn.pipeline import Pipeline

                    pre = ColumnTransformer([
                        ("num", "passthrough", [c for c in ALL_FEATURES if c not in CAT_FEATURES]),
                        ("cat", OneHotEncoder(handle_unknown="ignore", sparse_output=False), CAT_FEATURES),
                    ])
                    oh = Pipeline([("pre", pre)])
                    combo = pd.concat([X_train_used, X_input_used], axis=0)
                    combo_arr = oh.fit_transform(combo)
                    combo_df  = pd.DataFrame(combo_arr)

                    X_train_enc = combo_df.iloc[:-1, :].reset_index(drop=True)
                    X_input_enc = combo_df.iloc[-1:, :].reset_index(drop=True)

                # 5) ‡∏™‡πÄ‡∏Å‡∏•‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì cosine similarity
                from sklearn.preprocessing import StandardScaler
                from sklearn.metrics.pairwise import cosine_similarity

                scaler = StandardScaler()
                train_scaled = scaler.fit_transform(X_train_enc)
                input_scaled = scaler.transform(X_input_enc)

                sim = cosine_similarity(train_scaled, input_scaled).ravel()
                k = min(5, len(sim))
                confidence = float(np.mean(np.sort(sim)[-k:]))

                st.metric("‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• (Confidence)", f"{confidence * 100:.1f} %")
                if confidence >= 0.9:
                    st.success("‚úÖ ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ö‡∏ó‡∏µ‡πà‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏Ñ‡∏¢‡πÄ‡∏´‡πá‡∏ô ‚Üí ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏±‡πà‡∏ô‡πÑ‡∏î‡πâ‡∏™‡∏π‡∏á")
                elif confidence >= 0.7:
                    st.info("‚ÑπÔ∏è ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á ‚Üí ‡∏ô‡πà‡∏≤‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏ñ‡∏∑‡∏≠‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á")
                else:
                    st.warning("‚ö†Ô∏è ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á ‚Üí ‡∏£‡∏∞‡∏ß‡∏±‡∏á ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏≠‡∏≤‡∏à‡πÑ‡∏°‡πà‡πÅ‡∏°‡πà‡∏ô")

            except Exception as e:
                st.warning(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì confidence ‡πÑ‡∏î‡πâ: {e}")
        else:
            st.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö X_train.pkl ‚Äî ‡∏à‡∏∞‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏™‡∏î‡∏á Confidence Score ‡πÑ‡∏î‡πâ")

    except Exception as e:
        st.error(f"‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {e}")


































